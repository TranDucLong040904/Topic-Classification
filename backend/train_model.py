# ============================================
# TRAIN MODEL PHÃ‚N LOáº I TOPIC
# Train Topic Classification Model
# ============================================

import pandas as pd
import pickle
import os
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from underthesea import word_tokenize
import re

# ============================================
# Cáº¤U HÃŒNH - CONFIGURATION
# ============================================

# File input - Sá»¬A Äá»”I QUAN TRá»ŒNG
# Input file - IMPORTANT CHANGE
INPUT_FILE = 'data/huggingface_dataset.csv'

# ThÆ° má»¥c lÆ°u model
# Model output directory
OUTPUT_DIR = 'models'

# ============================================
# HÃ€M TIá»€N Xá»¬ LÃ - PREPROCESSING FUNCTIONS
# ============================================

def clean_text(text):
    """
    LÃ m sáº¡ch vÄƒn báº£n
    Clean text data
    """
    # Chuyá»ƒn vá» chá»¯ thÆ°á»ng
    # Convert to lowercase
    text = text.lower()
    
    # Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t, giá»¯ láº¡i chá»¯ cÃ¡i tiáº¿ng Viá»‡t
    # Remove special characters, keep Vietnamese letters
    text = re.sub(r'[^\w\sÃ¡Ã áº£Ã£áº¡Äƒáº¯áº±áº³áºµáº·Ã¢áº¥áº§áº©áº«áº­Ã©Ã¨áº»áº½áº¹Ãªáº¿á»á»ƒá»…á»‡Ã­Ã¬á»‰Ä©á»‹Ã³Ã²á»Ãµá»Ã´á»‘á»“á»•á»—á»™Æ¡á»›á»á»Ÿá»¡á»£ÃºÃ¹á»§Å©á»¥Æ°á»©á»«á»­á»¯á»±Ã½á»³á»·á»¹á»µÄ‘]', ' ', text)
    
    # Loáº¡i bá» khoáº£ng tráº¯ng thá»«a
    # Remove extra spaces
    text = ' '.join(text.split())
    
    return text


def tokenize_text(text):
    """
    TÃ¡ch tá»« tiáº¿ng Viá»‡t
    Vietnamese word tokenization
    """
    try:
        tokens = word_tokenize(text, format="text")
        return tokens
    except: 
        return text


def load_dataset(file_path):
    """
    Äá»c dataset tá»« file CSV
    Load dataset from CSV file
    """
    print(f"ğŸ“‚ Äang Ä‘á»c dataset tá»«: {file_path}")
    
    if not os.path.exists(file_path):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file: {file_path}")
        print("ğŸ’¡ Cháº¡y download_huggingface.py trÆ°á»›c!")
        return None
    
    df = pd.read_csv(file_path)
    print(f"âœ… ÄÃ£ Ä‘á»c {len(df)} máº«u")
    print(f"\nğŸ“Š PhÃ¢n bá»‘ topics:")
    print(df['topic'].value_counts())
    
    return df


def preprocess_data(df):
    """
    Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
    Preprocess data
    """
    print("\nğŸ§¹ Äang tiá»n xá»­ lÃ½ dá»¯ liá»‡u...")
    
    # LÃ m sáº¡ch vÄƒn báº£n
    # Clean text
    print("   - LÃ m sáº¡ch vÄƒn báº£n...")
    df['text_clean'] = df['text'].apply(clean_text)
    
    # TÃ¡ch tá»« tiáº¿ng Viá»‡t
    # Vietnamese word tokenization
    print("   - TÃ¡ch tá»« tiáº¿ng Viá»‡t (cÃ³ thá»ƒ máº¥t 1-2 phÃºt)...")
    df['text_tokenized'] = df['text_clean'].apply(tokenize_text)
    
    print("âœ… HoÃ n thÃ nh tiá»n xá»­ lÃ½")
    
    return df


# ============================================
# HÃ€M TRAIN MODEL - TRAINING FUNCTIONS
# ============================================

def train_model(df):
    """
    Train model phÃ¢n loáº¡i topic
    Train topic classification model
    """
    print("\nğŸ¤– Báº®T Äáº¦U TRAIN MODEL...\n")
    
    # Chia train/test (80/20)
    # Split train/test (80/20)
    X = df['text_tokenized']
    y = df['topic']
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"ğŸ“Š Dá»¯ liá»‡u train: {len(X_train)} máº«u")
    print(f"ğŸ“Š Dá»¯ liá»‡u test: {len(X_test)} máº«u")
    
    # TF-IDF Vectorizer
    # Convert text to TF-IDF features
    print("\nğŸ”¤ Äang táº¡o TF-IDF features...")
    vectorizer = TfidfVectorizer(
        max_features=5000,      # Giá»¯ 5000 tá»« quan trá»ng nháº¥t
        ngram_range=(1, 2),     # Unigram + Bigram
        min_df=1,               # Tá»« xuáº¥t hiá»‡n Ã­t nháº¥t 1 láº§n
        max_df=0.9              # Bá» tá»« xuáº¥t hiá»‡n >90% documents
    )
    
    X_train_tfidf = vectorizer.fit_transform(X_train)
    X_test_tfidf = vectorizer.transform(X_test)
    
    print(f"âœ… TF-IDF shape: {X_train_tfidf.shape}")
    
    # Train Naive Bayes Model
    # Train Multinomial Naive Bayes classifier
    print("\nğŸ“ Äang train Multinomial Naive Bayes...")
    model = MultinomialNB(alpha=0.1)
    model.fit(X_train_tfidf, y_train)
    
    print("âœ… Train model hoÃ n thÃ nh!")
    
    # ÄÃ¡nh giÃ¡ model
    # Evaluate model
    print("\nğŸ“ˆ ÄÃNH GIÃ MODEL:\n")
    
    # Accuracy trÃªn test set
    # Accuracy on test set
    y_pred = model.predict(X_test_tfidf)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"ğŸ¯ Accuracy: {accuracy*100:.2f}%")
    
    # Classification report chi tiáº¿t
    # Detailed classification report
    print("\nğŸ“Š Chi tiáº¿t theo tá»«ng topic:")
    print(classification_report(y_test, y_pred, zero_division=0))
    
    # Confusion Matrix
    print("\nğŸ”¢ Confusion Matrix:")
    cm = confusion_matrix(y_test, y_pred)
    print(cm)
    
    return model, vectorizer, accuracy


def save_model(model, vectorizer, output_dir=OUTPUT_DIR):
    """
    LÆ°u model vÃ  vectorizer
    Save model and vectorizer
    """
    print(f"\nğŸ’¾ Äang lÆ°u model...")
    
    # Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³
    # Create directory if not exists
    Path(output_dir).mkdir(exist_ok=True)
    
    # LÆ°u model
    # Save model
    model_path = Path(output_dir) / 'topic_classifier.pkl'
    with open(model_path, 'wb') as f:
        pickle.dump(model, f)
    print(f"âœ… Model Ä‘Ã£ lÆ°u táº¡i: {model_path}")
    
    # LÆ°u vectorizer
    # Save vectorizer
    vectorizer_path = Path(output_dir) / 'vectorizer.pkl'
    with open(vectorizer_path, 'wb') as f:
        pickle.dump(vectorizer, f)
    print(f"âœ… Vectorizer Ä‘Ã£ lÆ°u táº¡i:  {vectorizer_path}")


def test_prediction(model, vectorizer):
    """
    Test thá»­ dá»± Ä‘oÃ¡n vá»›i cÃ¢u máº«u
    Test prediction with sample sentences
    """
    print("\nğŸ§ª TEST THá»¬ Dá»° ÄOÃN:\n")
    
    # CÃ¡c cÃ¢u test máº«u
    # Sample test sentences
    test_texts = [
        "Äá»™i tuyá»ƒn Viá»‡t Nam giÃ nh chiáº¿n tháº¯ng 2-0 trong tráº­n Ä‘áº¥u vÃ²ng loáº¡i World Cup hÃ´m qua",
        "GiÃ¡ vÃ ng hÃ´m nay tÄƒng máº¡nh do áº£nh hÆ°á»Ÿng cá»§a thá»‹ trÆ°á»ng tháº¿ giá»›i",
        "Apple vá»«a ra máº¯t iPhone má»›i vá»›i nhiá»u tÃ­nh nÄƒng cÃ´ng nghá»‡ Ä‘á»™t phÃ¡",
        "Bá»™ GiÃ¡o dá»¥c cÃ´ng bá»‘ phÆ°Æ¡ng Ã¡n thi tá»‘t nghiá»‡p THPT nÄƒm nay",
        "BÃ¡c sÄ© khuyÃªn nÃªn Äƒn nhiá»u rau xanh Ä‘á»ƒ tÄƒng cÆ°á»ng sá»©c khá»e"
    ]
    
    for text in test_texts:
        # Tiá»n xá»­ lÃ½
        # Preprocess
        text_clean = clean_text(text)
        text_tokenized = tokenize_text(text_clean)
        
        # Vectorize
        text_tfidf = vectorizer.transform([text_tokenized])
        
        # Dá»± Ä‘oÃ¡n
        # Predict
        prediction = model.predict(text_tfidf)[0]
        proba = model.predict_proba(text_tfidf)[0]
        
        # Láº¥y top 3 topics
        # Get top 3 topics
        top_indices = proba.argsort()[-3:][::-1]
        top_topics = [(model.classes_[i], proba[i]*100) for i in top_indices]
        
        print(f"ğŸ“ Text: {text[: 70]}...")
        print(f"ğŸ¯ Dá»± Ä‘oÃ¡n: {prediction}")
        print(f"ğŸ“Š Top 3 topics:")
        for topic, prob in top_topics:
            print(f"   - {topic}: {prob:.2f}%")
        print()


# ============================================
# MAIN - CHáº Y CHÃNH
# ============================================

def main():
    print()
    print("=" * 70)
    print("TRAIN MODEL PHÃ‚N LOáº I TOPIC VÄ‚N Báº¢N TIáº¾NG VIá»†T")
    print("Train Vietnamese Text Topic Classification Model")
    print("=" * 70)
    print()
    
    # Load dataset
    df = load_dataset(INPUT_FILE)
    
    if df is None:
        return
    
    # Preprocess
    df = preprocess_data(df)
    
    # Train
    model, vectorizer, accuracy = train_model(df)
    
    # Save
    save_model(model, vectorizer)
    
    # Test
    test_prediction(model, vectorizer)
    
    # Káº¿t quáº£ cuá»‘i cÃ¹ng
    # Final results
    print("\n" + "=" * 70)
    print("âœ… HOÃ€N THÃ€NH BÆ¯á»šC 5.2 - TRAIN MODEL!")
    print("=" * 70)
    print(f"\nğŸ“Š Káº¿t quáº£:")
    print(f"   - Accuracy: {accuracy*100:.2f}%")
    print(f"   - Model: {OUTPUT_DIR}/topic_classifier.pkl")
    print(f"   - Vectorizer: {OUTPUT_DIR}/vectorizer.pkl")
    print(f"\nâ¡ï¸ Tiáº¿p theo: Test API backend (cháº¡y app.py)")


if __name__ == "__main__":
    main()